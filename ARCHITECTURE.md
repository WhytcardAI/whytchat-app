# WhytChat App - Architecture & Implementation Map

**Version**: 0.2.6  
**Framework**: Tauri v2 + React 18 + TypeScript  
**Backend**: Rust (SQLite, llama.cpp server management)  
**i18n**: Custom implementation (JSON files)  
**Canonical Locale**: English (`en`)

---

## ğŸ“ File Structure & Responsibilities

### Root Configuration Files

```
package.json              # Frontend dependencies & scripts
tsconfig.json             # TypeScript configuration
vite.config.ts            # Vite build config for Tauri
postcss.config.cjs        # PostCSS for Tailwind
tailwind.config.cjs       # Tailwind theme (dark mode support)
eslint.config.js          # ESLint rules (TypeScript, React)
README.md                 # User documentation
LICENSE                   # Open source license
CHANGELOG.md              # Version history
CONTRIBUTING.md           # Contribution guidelines
SECURITY.md               # Security policy
installer.iss             # Inno Setup script (Windows installer)
```

### Source Directory (`src/`)

#### Entry Point & Main App

```
index.html                # Tauri app HTML template
main.tsx                  # ReactDOM root render
â”œâ”€â”€ imports: React, ReactDOM, App, i18n
â”œâ”€â”€ sets: document.title = i18n.t("app.title")
â””â”€â”€ renders: <App /> in <React.StrictMode>

App.tsx                   # Main application component
â”œâ”€â”€ imports: useState, i18n, all view components, contexts, ErrorBoundary
â”œâ”€â”€ state:
â”‚   â”œâ”€â”€ currentView: "home" | "chat" | "settings" | "newConversation" | "conversations"
â”‚   â”œâ”€â”€ currentConversationId: string | null
â”‚   â”œâ”€â”€ showShortcuts: boolean
â”œâ”€â”€ structure:
â”‚   â”œâ”€â”€ <ErrorBoundary>
â”‚   â”œâ”€â”€ <ThemeProvider>
â”‚   â”œâ”€â”€ <ServerProvider>
â”‚   â”‚   â”œâ”€â”€ <TitleBar /> (custom window controls)
â”‚   â”‚   â”œâ”€â”€ <ServerStatusIndicator /> (fixed top-right)
â”‚   â”‚   â”œâ”€â”€ Conditional view rendering (Home, Chat, Settings, etc.)
â”‚   â”‚   â””â”€â”€ <ShortcutsHelp /> modal
â”œâ”€â”€ navigation: handleNavigate(view, conversationId?)
â””â”€â”€ keyboard shortcuts: Ctrl+H (home), Ctrl+N (new chat), Ctrl+L (list), Ctrl+/ (help), Esc (close modal)

index.css                 # Global Tailwind directives + dark mode styles
```

#### i18n System

```
i18n.ts                   # Custom i18n implementation
â”œâ”€â”€ imports: ./locales/fr.json, en.json, de.json, es.json, it.json, pt.json, nl.json, pl.json
â”œâ”€â”€ availableLocaleCodes: ["fr", "en", "de", "es", "it", "pt", "nl", "pl"]
â”œâ”€â”€ currentLocale: from localStorage or "fr" default
â”œâ”€â”€ i18n.t(key, fallback): Get nested translation (falls back to English)
â”œâ”€â”€ i18n.getLocale(): Get current locale
â”œâ”€â”€ i18n.setLocale(locale): Change locale + save to localStorage + emit "localechange" event
â””â”€â”€ get(obj, path, fallback): Nested key accessor (e.g., "chat.sendButton")
```

#### Contexts (`src/contexts/`)

```
ServerContext.tsx         # Global llama-server state management
â”œâ”€â”€ imports: createContext, useContext, useState, useEffect, useRef, invoke, listen (Tauri API)
â”œâ”€â”€ state:
â”‚   â”œâ”€â”€ status: "checking" | "starting" | "ready" | "stopped" | "error"
â”‚   â”œâ”€â”€ error: string | null
â”‚   â”œâ”€â”€ isReady: boolean (computed from status === "ready")
â”œâ”€â”€ methods:
â”‚   â”œâ”€â”€ startServer(modelPath?): Start llama-server with optional custom model path
â”‚   â”‚   â”œâ”€â”€ Pre-flight health check (avoid duplicate starts)
â”‚   â”‚   â”œâ”€â”€ Invoke "start_llama_server" or "start_llama_with_preset"
â”‚   â”‚   â”œâ”€â”€ Wait 2s for initialization
â”‚   â”‚   â”œâ”€â”€ Perform health check (max 30 attempts, 1s interval)
â”‚   â”‚   â””â”€â”€ Update status to "ready" or "error"
â”‚   â”œâ”€â”€ startForConversation(conversationId): Start server with conversation's preset
â”‚   â”‚   â””â”€â”€ Similar flow to startServer(), uses conversation DB record
â”‚   â””â”€â”€ stopServer(): Invoke "stop_llama_server", set status to "stopped"
â”œâ”€â”€ effects:
â”‚   â”œâ”€â”€ On mount: Check server status, auto-start if model available
â”‚   â”œâ”€â”€ Listen for window close â†’ auto-stop server before exit
â”‚   â”œâ”€â”€ Listen for "llama-server-status" event â†’ auto-start after install
â”‚   â””â”€â”€ Listen for "model-installed" event â†’ auto-start after download
â””â”€â”€ provides: ServerContext.Provider with { status, error, isReady, startServer, startForConversation, stopServer }

ThemeContext.tsx          # Light/dark theme management
â”œâ”€â”€ imports: createContext, useContext, useEffect, useState, getStorageItem, setStorageItem
â”œâ”€â”€ state: theme: "light" | "dark"
â”œâ”€â”€ initialization: From localStorage or system preference (window.matchMedia)
â”œâ”€â”€ methods:
â”‚   â”œâ”€â”€ setTheme(theme): Update state + localStorage
â”‚   â””â”€â”€ toggleTheme(): Switch between light/dark
â”œâ”€â”€ effect: Apply/remove "dark" class on document.documentElement
â””â”€â”€ provides: ThemeContext.Provider with { theme, toggleTheme, setTheme }
```

#### Hooks (`src/hooks/`)

```
useKeyboardShortcuts.ts   # Global keyboard shortcut manager
â”œâ”€â”€ imports: useEffect
â”œâ”€â”€ params: Array<{ key, ctrl?, alt?, shift?, handler, description }>
â”œâ”€â”€ logic:
â”‚   â”œâ”€â”€ Add window.addEventListener("keydown", ...)
â”‚   â”œâ”€â”€ Match key + modifiers (ctrl, alt, shift)
â”‚   â”œâ”€â”€ Prevent default if matched
â”‚   â””â”€â”€ Call handler()
â””â”€â”€ cleanup: Remove event listener on unmount
```

#### Utils (`src/utils/`)

```
storage.ts                # LocalStorage abstraction
â”œâ”€â”€ exports:
â”‚   â”œâ”€â”€ getStorageItem(key): JSON.parse or null
â”‚   â””â”€â”€ setStorageItem(key, value): JSON.stringify + localStorage.setItem
â””â”€â”€ purpose: Type-safe localStorage access

errors.ts                 # Error handling utilities
â”œâ”€â”€ exports:
â”‚   â”œâ”€â”€ AppError: Custom error class with code + message
â”‚   â””â”€â”€ handleError(error): Format error for UI display
â””â”€â”€ purpose: Consistent error messaging
```

#### RAG System (`src/rag/`)

```
types.ts                  # TypeScript types for RAG
â”œâ”€â”€ exports:
â”‚   â”œâ”€â”€ Document: { id, content, metadata }
â”‚   â”œâ”€â”€ Embedding: number[]
â”‚   â””â”€â”€ SearchResult: { document, score }
â””â”€â”€ purpose: Type safety for vector search

api.ts                    # RAG API calls (Tauri commands)
â”œâ”€â”€ imports: invoke (Tauri API), types
â”œâ”€â”€ functions:
â”‚   â”œâ”€â”€ indexDocument(document): Invoke "rag_index_document"
â”‚   â”œâ”€â”€ searchDocuments(query, topK): Invoke "rag_search_documents"
â”‚   â””â”€â”€ deleteDocument(id): Invoke "rag_delete_document"
â””â”€â”€ purpose: Frontend interface to Rust RAG backend
```

#### Components (`src/components/`)

**Main Views:**

```
Home/
â”œâ”€â”€ index.tsx             # Export wrapper
â””â”€â”€ Home.tsx              # Home screen
    â”œâ”€â”€ imports: i18n, useServer, lucide-react icons
    â”œâ”€â”€ props: onNavigate(view, conversationId?)
    â”œâ”€â”€ structure:
    â”‚   â”œâ”€â”€ Welcome message
    â”‚   â”œâ”€â”€ Server status indicator
    â”‚   â”œâ”€â”€ Quick actions: New Chat, View Conversations, Settings
    â”‚   â””â”€â”€ Recent conversations list (from DB)
    â””â”€â”€ uses: Tauri invoke("get_conversations") for recent chats

Chat/
â”œâ”€â”€ index.tsx             # Export wrapper
â”œâ”€â”€ Chat.tsx              # Chat interface
â”‚   â”œâ”€â”€ imports: useState, useEffect, useServer, invoke, lucide-react, MessageBubble, MessageToolbar
â”‚   â”œâ”€â”€ props: onNavigate, conversationId?
â”‚   â”œâ”€â”€ state:
â”‚   â”‚   â”œâ”€â”€ messages: Array<{ role, content }>
â”‚   â”‚   â”œâ”€â”€ inputValue: string
â”‚   â”‚   â”œâ”€â”€ isStreaming: boolean
â”‚   â”‚   â”œâ”€â”€ currentConversation: { id, title, preset_id }
â”‚   â”œâ”€â”€ methods:
â”‚   â”‚   â”œâ”€â”€ sendMessage(): Invoke "send_message_streaming" + handle stream
â”‚   â”‚   â”œâ”€â”€ stopGeneration(): Invoke "stop_generation"
â”‚   â”‚   â”œâ”€â”€ loadConversation(id): Invoke "get_conversation" + "get_messages"
â”‚   â”‚   â””â”€â”€ saveConversation(): Auto-save on message send
â”‚   â””â”€â”€ uses: EventSource or Tauri streaming for real-time responses
â””â”€â”€ components/
    â”œâ”€â”€ MessageBubble.tsx # Individual message display
    â”‚   â”œâ”€â”€ imports: i18n, lucide-react, streamdown (markdown rendering)
    â”‚   â”œâ”€â”€ props: message { role, content }, onCopy, onRegenerate
    â”‚   â”œâ”€â”€ structure:
    â”‚   â”‚   â”œâ”€â”€ Avatar (user/assistant icon)
    â”‚   â”‚   â”œâ”€â”€ Message content (markdown-formatted)
    â”‚   â”‚   â””â”€â”€ Toolbar (copy, regenerate buttons)
    â”‚   â””â”€â”€ uses: streamdown for markdown â†’ HTML
    â””â”€â”€ MessageToolbar.tsx # Message action buttons
        â”œâ”€â”€ props: onCopy, onRegenerate, onDelete
        â””â”€â”€ structure: Icon buttons for message actions

ConversationsList/
â”œâ”€â”€ index.tsx             # Conversations list view
    â”œâ”€â”€ imports: useState, useEffect, invoke, i18n, lucide-react
    â”œâ”€â”€ props: onNavigate
    â”œâ”€â”€ state: conversations: Array<{ id, title, created_at, preset_id }>
    â”œâ”€â”€ methods:
    â”‚   â”œâ”€â”€ loadConversations(): Invoke "get_conversations"
    â”‚   â”œâ”€â”€ deleteConversation(id): Invoke "delete_conversation"
    â”‚   â””â”€â”€ renameConversation(id, title): Invoke "update_conversation_title"
    â””â”€â”€ structure:
        â”œâ”€â”€ Search/filter bar
        â”œâ”€â”€ Conversations list (grouped by date?)
        â””â”€â”€ Empty state (no conversations)

NewConversation/
â”œâ”€â”€ index.tsx             # New conversation setup
    â”œâ”€â”€ imports: useState, useEffect, invoke, i18n, useServer
    â”œâ”€â”€ props: onNavigate
    â”œâ”€â”€ state:
    â”‚   â”œâ”€â”€ presets: Array<{ id, name, description }>
    â”‚   â”œâ”€â”€ selectedPreset: string | null
    â”‚   â”œâ”€â”€ title: string
    â”œâ”€â”€ methods:
    â”‚   â”œâ”€â”€ loadPresets(): Invoke "list_presets"
    â”‚   â”œâ”€â”€ createConversation(): Invoke "create_conversation" â†’ navigate to Chat
    â”‚   â””â”€â”€ startServer() if not ready
    â””â”€â”€ structure:
        â”œâ”€â”€ Preset selection (dropdown or cards)
        â”œâ”€â”€ Conversation title input
        â””â”€â”€ Create button

Settings/
â”œâ”€â”€ index.tsx             # Export wrapper
â””â”€â”€ Settings.tsx          # Settings panel
    â”œâ”€â”€ imports: useState, useEffect, invoke, i18n, useTheme
    â”œâ”€â”€ props: onNavigate
    â”œâ”€â”€ tabs:
    â”‚   â”œâ”€â”€ General: Language, theme, auto-start server
    â”‚   â”œâ”€â”€ Models: Download, delete, manage presets
    â”‚   â”œâ”€â”€ Advanced: Server port, context size, GPU settings
    â”‚   â””â”€â”€ About: Version, license, credits
    â””â”€â”€ uses: Invoke various settings commands (get/set_config)
```

**UI Components:**

```
ErrorBoundary/
â”œâ”€â”€ index.tsx             # React error boundary
    â”œâ”€â”€ state: hasError, error
    â”œâ”€â”€ static getDerivedStateFromError(error): Update state
    â”œâ”€â”€ componentDidCatch(error, errorInfo): Log to console/Sentry
    â””â”€â”€ render: Error UI with retry button or fallback to children

ServerStatusIndicator/
â”œâ”€â”€ index.tsx             # Server status badge
    â”œâ”€â”€ imports: useServer, i18n, lucide-react
    â”œâ”€â”€ displays: status (checking, starting, ready, stopped, error)
    â”œâ”€â”€ colors: gray (checking), yellow (starting), green (ready), red (error/stopped)
    â””â”€â”€ onClick: Show detailed status modal (optional)

ShortcutsHelp/
â”œâ”€â”€ index.tsx             # Keyboard shortcuts modal
    â”œâ”€â”€ imports: i18n, lucide-react
    â”œâ”€â”€ props: onClose
    â”œâ”€â”€ structure:
    â”‚   â”œâ”€â”€ Modal overlay
    â”‚   â”œâ”€â”€ Shortcuts list (key combos + descriptions)
    â”‚   â””â”€â”€ Close button (X or Esc)
    â””â”€â”€ shortcuts:
        â”œâ”€â”€ Ctrl+H: Go to Home
        â”œâ”€â”€ Ctrl+N: New Conversation
        â”œâ”€â”€ Ctrl+L: List Conversations
        â”œâ”€â”€ Ctrl+/: Show Shortcuts
        â””â”€â”€ Esc: Close Modal

TitleBar/
â”œâ”€â”€ index.tsx             # Custom window title bar (Tauri)
    â”œâ”€â”€ imports: getCurrentWindow, i18n, lucide-react
    â”œâ”€â”€ structure:
    â”‚   â”œâ”€â”€ App title + icon
    â”‚   â”œâ”€â”€ Window controls: Minimize, Maximize/Restore, Close
    â”‚   â””â”€â”€ data-tauri-drag-region (for dragging window)
    â””â”€â”€ methods:
        â”œâ”€â”€ minimize(): getCurrentWindow().minimize()
        â”œâ”€â”€ toggleMaximize(): getCurrentWindow().toggleMaximize()
        â””â”€â”€ close(): getCurrentWindow().close()

InstallLlamaServer/
â”œâ”€â”€ index.tsx             # llama-server installation wizard
    â”œâ”€â”€ imports: useState, invoke, listen, i18n
    â”œâ”€â”€ state:
    â”‚   â”œâ”€â”€ downloadProgress: number (0-100)
    â”‚   â”œâ”€â”€ installStatus: "idle" | "downloading" | "installing" | "done" | "error"
    â”‚   â”œâ”€â”€ error: string | null
    â”œâ”€â”€ methods:
    â”‚   â”œâ”€â”€ startDownload(): Invoke "download_llama_server"
    â”‚   â”œâ”€â”€ listenProgress(): Listen for "download-progress" events
    â”‚   â””â”€â”€ installServer(): Invoke "install_llama_server"
    â””â”€â”€ structure:
        â”œâ”€â”€ Installation steps (welcome, download, verify)
        â”œâ”€â”€ Progress bar
        â””â”€â”€ Error handling + retry

RAG/
â”œâ”€â”€ index.tsx             # RAG management UI
    â”œâ”€â”€ imports: useState, invoke, i18n, lucide-react
    â”œâ”€â”€ state:
    â”‚   â”œâ”€â”€ documents: Array<Document>
    â”‚   â”œâ”€â”€ searchQuery: string
    â”‚   â”œâ”€â”€ searchResults: Array<SearchResult>
    â”œâ”€â”€ methods:
    â”‚   â”œâ”€â”€ uploadDocument(): File picker â†’ invoke "rag_index_document"
    â”‚   â”œâ”€â”€ searchDocuments(): Invoke "rag_search_documents"
    â”‚   â””â”€â”€ deleteDocument(id): Invoke "rag_delete_document"
    â””â”€â”€ structure:
        â”œâ”€â”€ Document list (indexed files)
        â”œâ”€â”€ Upload button
        â”œâ”€â”€ Search bar
        â””â”€â”€ Search results display
```

### Locales (`src/locales/`)

```
en.json                   # Canonical English locale
fr.json                   # French translations
de.json                   # German translations
es.json                   # Spanish translations
it.json                   # Italian translations
pt.json                   # Portuguese translations
nl.json                   # Dutch translations
pl.json                   # Polish translations

Structure (nested JSON):
{
  "app": { "title": "WhytChat" },
  "home": { "welcome": "Welcome", ... },
  "chat": { "sendButton": "Send", ... },
  "settings": { "title": "Settings", ... },
  "shortcuts": { "goHome": "Go to Home", ... },
  ...
}
```

---

## ğŸ¦€ Rust Backend (`src-tauri/`)

### Configuration Files

```
Cargo.toml                # Rust dependencies
tauri.conf.json           # Tauri app configuration
build.rs                  # Tauri build script
pack-sources.json         # Model pack download sources
presets.json              # Llama model presets (context size, params)
```

### Rust Modules (`src-tauri/src/`)

```
main.rs                   # Tauri app entry point
â”œâ”€â”€ modules: db, llama, llama_install, rag
â”œâ”€â”€ state:
â”‚   â”œâ”€â”€ OverlayState: Mutex<bool> (window overlay mode)
â”‚   â”œâ”€â”€ DbState: Mutex<Connection> (SQLite database)
â”‚   â”œâ”€â”€ DownloadManager: Mutex<HashMap<String, DownloadEntry>> (active downloads)
â”œâ”€â”€ commands:
â”‚   â”œâ”€â”€ Window management: set_click_through, apply_overlay_bounds, toggle_overlay, set_overlay_mode
â”‚   â”œâ”€â”€ Downloads: download_model_pack, cancel_download, get_download_state, cleanup_downloads
â”‚   â”œâ”€â”€ Database: Proxies to db.rs functions
â”‚   â”œâ”€â”€ Llama server: Proxies to llama.rs functions
â”‚   â”œâ”€â”€ RAG: Proxies to rag.rs functions
â””â”€â”€ setup:
    â”œâ”€â”€ Initialize SQLite database (db::init_db)
    â”œâ”€â”€ Register Tauri commands
    â””â”€â”€ Listen for window events (close, overlay mode)

db.rs                     # SQLite database operations
â”œâ”€â”€ tables:
â”‚   â”œâ”€â”€ conversations: (id, title, created_at, updated_at, preset_id)
â”‚   â”œâ”€â”€ messages: (id, conversation_id, role, content, created_at)
â”‚   â””â”€â”€ settings: (key, value)
â”œâ”€â”€ functions:
â”‚   â”œâ”€â”€ init_db(app_handle): Create tables if not exist
â”‚   â”œâ”€â”€ create_conversation(conn, title, preset_id): Insert conversation
â”‚   â”œâ”€â”€ get_conversations(conn): List all conversations (ordered by updated_at DESC)
â”‚   â”œâ”€â”€ get_conversation(conn, id): Get single conversation
â”‚   â”œâ”€â”€ update_conversation_title(conn, id, title): Rename conversation
â”‚   â”œâ”€â”€ delete_conversation(conn, id): Delete conversation + messages
â”‚   â”œâ”€â”€ create_message(conn, conv_id, role, content): Insert message
â”‚   â”œâ”€â”€ get_messages(conn, conv_id): List messages for conversation
â”‚   â”œâ”€â”€ get_setting(conn, key): Get setting value
â”‚   â””â”€â”€ set_setting(conn, key, value): Update setting value
â””â”€â”€ uses: rusqlite crate

llama.rs                  # llama-server lifecycle management
â”œâ”€â”€ state: Static LLAMA_PROCESS: Mutex<Option<Child>> (server subprocess)
â”œâ”€â”€ functions:
â”‚   â”œâ”€â”€ check_llama_server(): Check if llama-server binary exists + is running
â”‚   â”œâ”€â”€ start_llama_server(model_path, ctx_size): Spawn llama-server subprocess
â”‚   â”‚   â”œâ”€â”€ Args: --model, --ctx-size, --port 8080, --host 127.0.0.1
â”‚   â”‚   â””â”€â”€ Store process handle in LLAMA_PROCESS
â”‚   â”œâ”€â”€ start_llama_with_preset(preset_id): Load preset from presets.json â†’ start_llama_server
â”‚   â”œâ”€â”€ start_llama_for_conversation(conv_id): Load conversation's preset_id â†’ start_llama_with_preset
â”‚   â”œâ”€â”€ stop_llama_server(): Kill LLAMA_PROCESS subprocess
â”‚   â”œâ”€â”€ health_check_llama_server(): HTTP GET http://127.0.0.1:8080/health
â”‚   â”œâ”€â”€ send_message_streaming(prompt, system_prompt): HTTP POST /completion with streaming
â”‚   â”œâ”€â”€ stop_generation(): Send interrupt signal to server
â”‚   â””â”€â”€ get_first_installed_preset(): Find first preset with existing model file
â””â”€â”€ uses: std::process::Command, reqwest (HTTP client)

llama_install.rs          # llama-server installation & updates
â”œâ”€â”€ functions:
â”‚   â”œâ”€â”€ download_llama_server(app_handle): Download llama-server binary for current platform
â”‚   â”‚   â”œâ”€â”€ Emit "download-progress" events
â”‚   â”‚   â””â”€â”€ Save to app_data_dir/llama-bin/
â”‚   â”œâ”€â”€ install_llama_server(app_handle): Unzip/chmod +x downloaded binary
â”‚   â”œâ”€â”€ check_llama_server_updates(): Check GitHub releases for new version
â”‚   â”œâ”€â”€ download_model_pack(app_handle, pack_id): Download model from pack-sources.json
â”‚   â”‚   â”œâ”€â”€ Emit "download-progress" events
â”‚   â”‚   â””â”€â”€ Save to app_data_dir/models/{pack_id}/
â”‚   â”œâ”€â”€ get_installed_packs(): List downloaded model packs
â”‚   â””â”€â”€ delete_model_pack(pack_id): Remove model files
â””â”€â”€ uses: reqwest (HTTP), tokio::fs (async file I/O), futures_util (stream)

rag.rs                    # RAG (Retrieval-Augmented Generation)
â”œâ”€â”€ functions:
â”‚   â”œâ”€â”€ rag_index_document(doc_path): Parse document, generate embeddings, store in vector DB
â”‚   â”œâ”€â”€ rag_search_documents(query, top_k): Semantic search in vector DB
â”‚   â”œâ”€â”€ rag_delete_document(doc_id): Remove document from index
â”‚   â””â”€â”€ rag_get_embeddings(text): Call llama-server /embeddings endpoint
â””â”€â”€ uses: SQLite (vector storage), llama.cpp embeddings API
```

### Tauri Configuration (`tauri.conf.json`)

```json
{
  "identifier": "com.whytcard.whytchat",
  "productName": "WhytChat",
  "version": "0.2.6",
  "windows": [
    {
      "title": "WhytChat",
      "width": 1200,
      "height": 800,
      "resizable": true,
      "fullscreen": false,
      "decorations": false, // Custom title bar
      "transparent": false
    }
  ],
  "security": {
    "csp": "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'"
  },
  "allowlist": {
    "all": false,
    "fs": { "all": true },
    "dialog": { "all": true },
    "http": { "all": true },
    "shell": { "all": true },
    "window": { "all": true }
  }
}
```

---

## ğŸ”„ Data Flow & Component Relationships

### Application Bootstrap

```
1. main.tsx
   â”œâ”€â”€ Initialize i18n (load locale files)
   â”œâ”€â”€ Set document.title from i18n
   â””â”€â”€ Render <App /> in StrictMode

2. App.tsx
   â”œâ”€â”€ Wrap in <ErrorBoundary>
   â”œâ”€â”€ Wrap in <ThemeProvider> (light/dark mode)
   â”œâ”€â”€ Wrap in <ServerProvider> (llama-server state)
   â”œâ”€â”€ Register global keyboard shortcuts
   â””â”€â”€ Render current view (Home, Chat, Settings, etc.)

3. ServerContext initialization
   â”œâ”€â”€ Check llama-server status (invoke "check_llama_server")
   â”œâ”€â”€ If installed + not running: auto-start if model available
   â”œâ”€â”€ Listen for window close â†’ auto-stop server
   â””â”€â”€ Listen for model install events â†’ auto-start server
```

### Component Dependencies Graph

```
App.tsx
â”œâ”€â”€â”€ ThemeProvider (context)
â”œâ”€â”€â”€ ServerProvider (context)
â”‚    â””â”€â”€â”€ Manages llama-server lifecycle
â”œâ”€â”€â”€ TitleBar (custom window controls)
â”œâ”€â”€â”€ ServerStatusIndicator (global status badge)
â”œâ”€â”€â”€ Home (props: onNavigate)
â”‚    â””â”€â”€â”€ Lists recent conversations (invoke "get_conversations")
â”œâ”€â”€â”€ Chat (props: onNavigate, conversationId?)
â”‚    â”œâ”€â”€â”€ MessageBubble (message display + markdown)
â”‚    â”œâ”€â”€â”€ MessageToolbar (copy, regenerate actions)
â”‚    â””â”€â”€â”€ Uses ServerContext for streaming
â”œâ”€â”€â”€ ConversationsList (props: onNavigate)
â”‚    â””â”€â”€â”€ CRUD operations (invoke "get/delete/update_conversation")
â”œâ”€â”€â”€ NewConversation (props: onNavigate)
â”‚    â””â”€â”€â”€ Preset selection + server start
â”œâ”€â”€â”€ Settings (props: onNavigate)
â”‚    â”œâ”€â”€â”€ Language, theme (useTheme)
â”‚    â””â”€â”€â”€ Model downloads (invoke "download_model_pack")
â”œâ”€â”€â”€ RAG (optional feature)
â”‚    â””â”€â”€â”€ Document management (invoke "rag_*")
â”œâ”€â”€â”€ InstallLlamaServer (first-run wizard)
â”‚    â””â”€â”€â”€ Download/install llama-server binary
â””â”€â”€â”€ ShortcutsHelp (modal)
     â””â”€â”€â”€ Keyboard shortcuts reference
```

### State Management

**Contexts:**

- **ServerContext**: Global llama-server status, start/stop methods
- **ThemeContext**: Light/dark mode, persisted in localStorage

**Local State:**

- **App.tsx**: currentView, currentConversationId, showShortcuts
- **Chat.tsx**: messages, inputValue, isStreaming
- **Settings.tsx**: presets, downloadProgress, settings values
- **ConversationsList.tsx**: conversations array

**Persistent State:**

- **SQLite**: Conversations, messages, settings
- **LocalStorage**: Theme, locale, user preferences
- **Filesystem**: Model files, llama-server binary

### Key Data Flows

#### 1. Chat Message Flow

```
User types message â†’ Chat.tsx
â”œâ”€ Update inputValue state
â”œâ”€ onClick Send â†’ sendMessage()
â”‚  â”œâ”€ Save message to DB (invoke "create_message")
â”‚  â”œâ”€ Call llama-server API (invoke "send_message_streaming")
â”‚  â”œâ”€ Listen for streaming events (Server-Sent Events or Tauri stream)
â”‚  â”œâ”€ Update messages state incrementally
â”‚  â””â”€ Save assistant response to DB
â””â”€ Render MessageBubble for each message
```

#### 2. Server Lifecycle

```
App mounts â†’ ServerContext.useEffect
â”œâ”€ Check server status (invoke "check_llama_server")
â”œâ”€ If not running + model available:
â”‚  â”œâ”€ Auto-start server (invoke "start_llama_with_preset")
â”‚  â”œâ”€ Wait 2s for initialization
â”‚  â”œâ”€ Health check loop (30 attempts, 1s interval)
â”‚  â””â”€ Update status to "ready" or "error"
â””â”€ Listen for events:
   â”œâ”€ "llama-server-status" â†’ auto-start after install
   â”œâ”€ "model-installed" â†’ auto-start after download
   â””â”€ Window close â†’ stop_llama_server()
```

#### 3. Conversation Creation

```
User â†’ NewConversation
â”œâ”€ Select preset (invoke "list_presets")
â”œâ”€ Enter title
â”œâ”€ Click Create
â”‚  â”œâ”€ invoke "create_conversation" â†’ returns conv_id
â”‚  â”œâ”€ Start server if not ready (startForConversation(conv_id))
â”‚  â””â”€ Navigate to Chat view (onNavigate("chat", conv_id))
â””â”€ Chat view loads conversation (invoke "get_conversation", "get_messages")
```

#### 4. Theme Toggle

```
User clicks theme button â†’ Settings.tsx
â”œâ”€ useTheme().toggleTheme()
â”œâ”€ ThemeContext updates state ("light" â†’ "dark")
â”œâ”€ Save to localStorage ("whytchat-theme")
â”œâ”€ ThemeContext.useEffect triggers
â””â”€ Add/remove "dark" class on document.documentElement
```

---

## ğŸ“¦ NPM Dependencies

### Production Dependencies

```json
{
  "@tauri-apps/api": "^2.0.0", // Tauri JS API (invoke, events, window)
  "@tauri-apps/plugin-dialog": "^2.0.0", // File picker dialogs
  "lucide-react": "^0.548.0", // Icon library
  "react": "^18.3.1", // React core
  "react-dom": "^18.3.1", // React DOM
  "streamdown": "^1.4.0" // Markdown rendering
}
```

### Dev Dependencies

```json
{
  "@eslint/js": "^9.38.0",
  "@tailwindcss/postcss": "^4.1.16",
  "@tauri-apps/cli": "^2.0.0", // Tauri CLI (dev, build)
  "@types/react": "^18.2.45",
  "@types/react-dom": "^18.2.18",
  "@typescript-eslint/eslint-plugin": "^8.46.2",
  "@typescript-eslint/parser": "^8.46.2",
  "@vitejs/plugin-react": "^4.3.1",
  "autoprefixer": "^10.4.21",
  "eslint": "^9.38.0",
  "eslint-plugin-react": "^7.37.5",
  "eslint-plugin-react-hooks": "^7.0.1",
  "eslint-plugin-unused-imports": "^4.3.0",
  "jscpd": "^4.0.5", // Duplicate code detection
  "postcss": "^8.5.6",
  "prettier": "^3.3.3",
  "tailwindcss": "^3.4.14",
  "typescript": "^5.6.3",
  "vite": "^5.4.0"
}
```

### Rust Dependencies (Cargo.toml)

```toml
[dependencies]
tauri = { version = "2.0", features = ["all"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
rusqlite = { version = "0.30", features = ["bundled"] }
reqwest = { version = "0.11", features = ["stream", "json"] }
tokio = { version = "1.35", features = ["full"] }
futures-util = "0.3"
```

---

## ğŸ¯ Feature Completeness Checklist

### Core Features

- [x] **Multi-view navigation** (Home, Chat, Settings, Conversations, New Conversation)
- [x] **Custom i18n** (8 languages: en, fr, de, es, it, pt, nl, pl)
- [x] **Dark mode** (ThemeContext + Tailwind dark: classes)
- [x] **Custom title bar** (TitleBar component for frameless window)
- [x] **Global keyboard shortcuts** (useKeyboardShortcuts hook)
- [x] **Error boundary** (ErrorBoundary component)
- [x] **Server lifecycle** (ServerContext auto-start/stop)

### Chat Features

- [x] **Real-time streaming** (Server-Sent Events from llama-server)
- [x] **Markdown rendering** (streamdown library)
- [x] **Message persistence** (SQLite database)
- [x] **Conversation management** (CRUD operations)
- [x] **Message actions** (copy, regenerate, delete)
- [x] **Stop generation** (interrupt streaming)

### Model Management

- [x] **Preset system** (presets.json with context size, params)
- [x] **Model download** (llama_install.rs with progress events)
- [x] **Installation wizard** (InstallLlamaServer component)
- [x] **Auto-start server** (after model install)
- [x] **Health checks** (retry logic for server startup)

### Settings

- [x] **Language switcher** (i18n.setLocale + localechange event)
- [x] **Theme toggle** (ThemeContext)
- [x] **Model downloads** (pack-sources.json)
- [x] **Server configuration** (port, context size, GPU settings)
- [x] **About section** (version, license, credits)

### Advanced Features

- [x] **RAG system** (rag.rs for document indexing/search)
- [x] **Overlay mode** (always-on-top, compact window)
- [x] **Download manager** (DownloadManager state with cancel support)
- [x] **Server status indicator** (ServerStatusIndicator component)
- [x] **Keyboard shortcuts help** (ShortcutsHelp modal)

### Developer Experience

- [x] **TypeScript** (full type coverage)
- [x] **ESLint** (React, TypeScript, unused imports)
- [x] **Prettier** (code formatting)
- [x] **i18n parity check** (`scripts/check-i18n.cjs`)
- [x] **Version check** (`scripts/check-version.cjs`)
- [x] **Quality gates** (`check:quality` script)

### CI/CD Integration

- [x] **GitHub Actions release workflow** (`.github/workflows/release.yml`)
  - Triggered by `v*.*.*` tags
  - Windows-only build (tauri-action)
  - Outputs: .msi + .nsis.zip
  - Pre-build: i18n check
- [x] **Installer script** (`installer.iss` for Inno Setup)

---

## ğŸš€ Implementation Priorities

### Phase 1: Core Structure (MUST HAVE)

1. âœ… Tauri configuration (`tauri.conf.json`, `Cargo.toml`)
2. âœ… Entry point (`main.tsx`, `App.tsx`, `i18n.ts`)
3. âœ… Contexts (`ServerContext.tsx`, `ThemeContext.tsx`)
4. âœ… Utils (`storage.ts`, `errors.ts`)
5. âœ… Rust backend (`main.rs`, `db.rs`, `llama.rs`)

### Phase 2: UI Components (MUST HAVE)

6. âœ… Layout (`TitleBar`, `ServerStatusIndicator`, `ErrorBoundary`)
7. âœ… Views (`Home`, `Chat`, `Settings`, `ConversationsList`, `NewConversation`)
8. âœ… Chat sub-components (`MessageBubble`, `MessageToolbar`)

### Phase 3: Advanced Features (SHOULD HAVE)

9. âœ… RAG system (`rag.rs`, `RAG` component)
10. âœ… Model management (`llama_install.rs`, `InstallLlamaServer`)
11. âœ… Keyboard shortcuts (`useKeyboardShortcuts`, `ShortcutsHelp`)
12. âœ… Overlay mode (main.rs commands)

### Phase 4: Polish & Optimization (NICE TO HAVE)

13. âœ… Dark mode (Tailwind dark: variants)
14. âœ… Download manager (progress tracking, cancel)
15. âœ… Auto-updates (check_llama_server_updates)
16. âœ… Quality checks (ESLint, Prettier, i18n parity)

---

## ğŸ”§ Migration Strategy

### Step 1: Setup & Configuration

- Copy `package.json`, `tsconfig.json`, `vite.config.ts`, `tailwind.config.cjs`, `postcss.config.cjs`
- Copy `src-tauri/Cargo.toml`, `tauri.conf.json`, `build.rs`
- Install dependencies: `npm install` + `cargo build` (Rust)

### Step 2: Rust Backend

- Copy `src-tauri/src/main.rs`, `db.rs`, `llama.rs`, `llama_install.rs`, `rag.rs`
- Copy `pack-sources.json`, `presets.json`
- Test Tauri commands: `npm run tauri dev`

### Step 3: Frontend Core

- Copy `src/main.tsx`, `App.tsx`, `index.css`, `i18n.ts`
- Copy `src/contexts/`, `src/hooks/`, `src/utils/`
- Copy `src/locales/` (all 8 JSON files)

### Step 4: UI Components

- Copy `src/components/Home/`, `Chat/`, `Settings/`, etc.
- Copy sub-components (`MessageBubble`, `MessageToolbar`, etc.)
- Verify all imports resolve correctly

### Step 5: Assets & Configuration

- Copy `src/index.html`, `src/favicon.svg`
- Copy `installer.iss` (Windows installer script)
- Copy CI/CD files (`.github/workflows/release.yml`, `scripts/`)

### Step 6: Testing & Validation

- Run `npm run check:i18n` (verify translation parity)
- Run `npm run check:version` (verify version consistency)
- Run `npm run check:lint` (ESLint)
- Run `npm run tauri build` (test production build)

---

## ğŸ§ª Testing Checklist

### Functional Tests

- [ ] App launches successfully (Tauri window appears)
- [ ] Server auto-starts if model is installed
- [ ] Language switcher changes UI language
- [ ] Theme toggle switches light/dark mode
- [ ] Create new conversation â†’ starts server â†’ loads Chat view
- [ ] Send message â†’ streams response â†’ saves to DB
- [ ] Stop generation interrupts streaming
- [ ] List conversations â†’ displays all saved chats
- [ ] Delete conversation â†’ removes from DB
- [ ] Keyboard shortcuts work (Ctrl+H, Ctrl+N, Ctrl+L, Ctrl+/)

### Visual Tests

- [ ] Custom title bar displays correctly (minimize, maximize, close)
- [ ] Server status indicator shows correct colors (gray, yellow, green, red)
- [ ] Dark mode applies to all components
- [ ] Markdown renders correctly in chat messages (code blocks, lists, etc.)
- [ ] Icons display correctly (Lucide React)
- [ ] Responsive layout (min width 800px for desktop)

### Performance Tests

- [ ] App startup time < 2s
- [ ] Message streaming has no visible lag
- [ ] Server health check completes within 30s
- [ ] DB queries execute in < 100ms
- [ ] No memory leaks (server process properly stopped on exit)

### Integration Tests

- [ ] llama-server binary downloads successfully
- [ ] Model packs download with progress tracking
- [ ] Server starts with correct preset parameters
- [ ] RAG document indexing works
- [ ] Overlay mode positions window correctly

### i18n Tests

- [ ] `npm run check:i18n` passes (all 8 locales have same keys)
- [ ] All UI strings use `i18n.t()` (no hardcoded English)
- [ ] Language change persists after app restart

### CI/CD Tests

- [ ] GitHub Actions release workflow builds successfully
- [ ] Windows .msi installer works
- [ ] .nsis.zip portable version works
- [ ] i18n check runs in CI

---

## ğŸ“ Notes

- **Custom i18n**: No react-i18next (lightweight custom implementation)
- **SQLite only**: No cloud sync (local-first architecture)
- **Windows-first**: macOS/Linux support paused (focus on single platform)
- **No auto-updates**: Manual download from GitHub Releases
- **Version synchronization**: `package.json` and `src-tauri/Cargo.toml` versions MUST match. Use `npm run check:version` to validate before releases. Current source shows 0.2.6 (package.json) vs 0.2.1 (Cargo.toml) - requires sync
- **Frameless window**: Custom title bar for consistent cross-platform UI
- **Streaming responses**: Server-Sent Events from llama-server /completion endpoint
- **RAG optional**: Feature flag in Settings (disabled by default)
- **Overlay mode**: Experimental feature for always-on-top mini-chat

---

## ğŸ†˜ Common Issues & Solutions

### Issue: Server fails to start

- **Cause**: llama-server binary not found or model file missing
- **Fix**: Run InstallLlamaServer wizard, verify model path in presets.json

### Issue: Streaming stops mid-response

- **Cause**: Server crashed or network timeout
- **Fix**: Check server logs (stderr), restart server, increase timeout

### Issue: Database locked error

- **Cause**: Concurrent writes to SQLite (rusqlite mutex issue)
- **Fix**: Use `DbState(Mutex<Connection>)` pattern, avoid long transactions

### Issue: Dark mode not applying

- **Cause**: Tailwind `darkMode: 'class'` not configured or missing `dark:` variants
- **Fix**: Verify `tailwind.config.cjs` has `darkMode: 'class'`, add `dark:bg-*` classes

### Issue: i18n keys not found

- **Cause**: Missing keys in locale files or nested key access failure
- **Fix**: Run `npm run check:i18n`, verify key paths match (e.g., `chat.sendButton`)

### Issue: Build fails with Rust error

- **Cause**: Missing Rust dependencies or incorrect target triple
- **Fix**: Run `cargo build` separately, check Cargo.toml, install toolchain

### Issue: Keyboard shortcuts not working

- **Cause**: Event listener not attached or preventDefault missing
- **Fix**: Check useKeyboardShortcuts hook, verify `window.addEventListener` runs

---

**Last Updated**: 2025-11-15  
**Maintained By**: WhytCard V2 Team  
**Status**: âœ… Ready for implementation
