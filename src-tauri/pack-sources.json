[
  {
    "id": "llama32_3b_light",
    "url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
    "filename": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
    "sizeBytes": 2020000000
  },
  {
    "id": "mistral_balanced",
    "url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf",
    "filename": "mistral-7b-instruct-v0.2.Q4_K_M.gguf",
    "sizeBytes": 4370000000
  },
  {
    "id": "llama31_8b_heavy",
    "url": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
    "filename": "Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
    "sizeBytes": 5700000000
  },
  {
    "id": "qwen_coder_1.5b_light",
    "url": "https://huggingface.co/bartowski/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-Q4_K_M.gguf",
    "filename": "Qwen2.5-Coder-1.5B-Instruct-Q4_K_M.gguf",
    "sizeBytes": 1000000000
  },
  {
    "id": "qwen_coder_fast",
    "url": "https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-Q4_K_M.gguf",
    "filename": "Qwen2.5-Coder-7B-Instruct-Q4_K_M.gguf",
    "sizeBytes": 5020807168
  },
  {
    "id": "qwen_coder_14b_heavy",
    "url": "https://huggingface.co/bartowski/Qwen2.5-Coder-14B-GGUF/resolve/main/Qwen2.5-Coder-14B-Q5_K_M.gguf",
    "filename": "Qwen2.5-Coder-14B-Q5_K_M.gguf",
    "sizeBytes": 9800000000
  },
  {
    "id": "openhermes_balanced",
    "url": "https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf",
    "filename": "openhermes-2.5-mistral-7b.Q4_K_M.gguf",
    "sizeBytes": 4370000000
  },
  {
    "id": "wizardlm_heavy",
    "url": "https://huggingface.co/bartowski/WizardLM-2-7B-GGUF/resolve/main/WizardLM-2-7B-Q5_K_M.gguf",
    "filename": "WizardLM-2-7B-Q5_K_M.gguf",
    "sizeBytes": 5400000000
  },
  {
    "id": "nous_hermes_balanced",
    "url": "https://huggingface.co/bartowski/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO-Q4_K_M.gguf",
    "filename": "Nous-Hermes-2-Mistral-7B-DPO-Q4_K_M.gguf",
    "sizeBytes": 4370000000
  },
  {
    "id": "dolphin_heavy",
    "url": "https://huggingface.co/bartowski/dolphin-2.8-mistral-7b-v02-GGUF/resolve/main/dolphin-2.8-mistral-7b-v02-Q5_K_M.gguf",
    "filename": "dolphin-2.8-mistral-7b-v02-Q5_K_M.gguf",
    "sizeBytes": 5400000000
  }
]
